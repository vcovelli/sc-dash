version: "3.8"

services:
  postgres:
    image: postgres:13
    env_file:
      - .env
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - pg_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    command: >
      sh -c "python manage.py migrate &&
             python manage.py runserver 0.0.0.0:8000"
    volumes:
      - ./backend:/app
    ports:
      - "8000:8000"
    depends_on:
      - postgres
    env_file:
      - .env

  airflow-webserver:
    image: apache/airflow:2.7.3
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@postgres/${DB_NAME}
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
    volumes:
      - ./backend/airflow/dags:/opt/airflow/dags
      - ./backend/backend_scripts:/opt/airflow/backend_scripts
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    command: >
      bash -c "airflow db init &&
               airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin &&
               airflow webserver"

  airflow-scheduler:
    image: apache/airflow:2.7.3
    restart: always
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@postgres/${DB_NAME}
    volumes:
      - ./backend/airflow/dags:/opt/airflow/dags
      - ./backend/airflow/logs:/opt/airflow/logs
      - ./backend/airflow/plugins:/opt/airflow/plugins
      - ./backend/backend_scripts:/opt/airflow/backend_scripts
    command: scheduler

volumes:
  pg_data:
